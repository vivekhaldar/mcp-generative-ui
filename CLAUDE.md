# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

MCP Generative UI Wrapper is a proxy layer that wraps any "plain" MCP server (tools-only) and automatically generates interactive UI resources using an LLM at runtime. This enables rapid prototyping of MCP Apps from existing tool-based MCP servers without modifying the underlying server.

**Current Status**: Implemented and working. Supports both MCP Apps and OpenAI Apps SDK standards, pipe composition with mcpblox.

## Key Concepts

- **MCP Apps**: Extension to MCP allowing servers to provide rich interactive UIs rendered in conversation
- **Tool-UI Linkage**: Tools declare UI resources via `_meta.ui.resourceUri` pointing to `ui://` URIs
- **On-Demand Generation**: UIs are generated by LLM when first requested, then cached
- **Iterative Refinement**: Users can request UI changes via natural language (e.g., "make the table sortable")

## Architecture

The wrapper sits between the MCP host (e.g., Claude Desktop) and the underlying MCP server:

```
MCP Host → Generative UI Wrapper → Underlying MCP Server
```

Key components:
- **MCP Server Interface**: Handles MCP protocol, adds `_meta.ui.resourceUri` to tools
- **Tool Proxy**: Forwards tool calls to upstream server transparently
- **UI Generator**: LLM-powered HTML generation with prompt management and retry logic
- **Cache Manager**: LRU cache keyed by tool schema hash + refinement history

## Design Documents

- `docs/PRODUCT_SPEC.md` - Functional requirements, user stories, data models
- `docs/PRODUCT_SPEC-design.md` - Technical design, architecture, implementation task breakdown
- `docs/PRODUCT_SPEC-design-critiques/` - Design review feedback and responses

## Implementation Guidelines (from design doc)

### UI Generation
- Generated UIs must be self-contained (single HTML with inline JS/CSS)
- Use `@modelcontextprotocol/ext-apps` App API (host-provided, not CDN)
- Always include JSON fallback display (output schemas are unavailable)
- Hard timeout: 15 seconds for generation, then serve minimal UI

### Cache Key Computation
```
key = hash(tool_name + tool_hash + refinement_hash + config_hash)
```
Where:
- `tool_hash = SHA256(canonicalJson(name + description + inputSchema))`
- `refinement_hash = SHA256(refinements.join('|'))`
- `config_hash = SHA256(promptVersion + templateVersion + llmModel + ...)`

### Wrapper Tools (prefixed with `_ui_`)
- `_ui_refine` - Apply natural language refinement to a tool's UI
- `_ui_list` - List all tools and their UI generation status
- `_ui_inspect` - Get generation details for a specific tool
- `_ui_regenerate` - Force cache bypass and regenerate UI
- `_ui_refresh_tools` - Re-fetch tools from upstream server

### Error Handling
- All LLM failures fall back to minimal UI template
- Generated UIs include error boundaries with raw JSON fallback
- Tool removal from upstream triggers cache invalidation

## Transport Support
- Stdio, SSE, HTTP (bearer auth), and Streamable HTTP transports for upstream connection
- Wrapper exposes itself as Streamable HTTP MCP server

## Pipe Composition
- Reads upstream URL from stdin when piped (compatible with mcpblox pipe protocol)
- Writes own URL to stdout for downstream pipe consumers
- Defaults to OS-assigned port when stdout is piped
- All logging goes to stderr to keep stdout clean for pipe protocol
- Key files: `src/pipe.ts` (protocol), `src/log.ts` (stderr logging)

## Target Host
V1 explicitly targets Claude Desktop and ChatGPT (via chatgpt-app-sim) as primary MCP hosts with single-user operation.
